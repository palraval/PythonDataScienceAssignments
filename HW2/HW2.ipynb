{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Markov Models of Natural Language\n",
    "\n",
    "### Name: Palash Raval\n",
    "### Collaborators: None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework focuses on topics related to string manipulation, dictionaries, and simulations. \n",
    "\n",
    "I encourage collaborating with your peers, but the final text, code, and comments in this homework assignment should still be written by you. Please check the collaboration policy.\n",
    "\n",
    "Submission instructions: \n",
    "- Submit `HW2.py` and `HW2.ipynb` compressed in a one zip file on Gradescope under \"HW2 - Autograder\". Do **NOT** change the file name. \n",
    "- Convert this notebook into a pdf file and submit it on GradeScope under \"HW2 - PDF\". Make sure your text outputs in the latter problems are visible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Models\n",
    "\n",
    "Many of you may have encountered the output of machine learning models which, when \"seeded\" with a small amount of text, produce a larger corpus of text which is expected to be similar or relevant to the seed text. For example, there's been a lot of buzz about the new [GPT-3 model](https://en.wikipedia.org/wiki/GPT-3), related to its [carbon footprint](https://www.forbes.com/sites/robtoews/2020/06/17/deep-learnings-climate-change-problem/#2781c1b16b43), [bigoted tendencies](https://medium.com/fair-bytes/how-biased-is-gpt-3-5b2b91f1177), and, yes, impressive (and often [humorous](https://aiweirdness.com/)) [ability to replicate human-like text in response to prompts.](https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/) \n",
    "\n",
    "We are not going to program a complicated deep learning model, but we will construct a much simpler language model that performs a similar task. Using tools like iteration and dictionaries, we will create a family of **Markov language models** for generating text. For the purposes of this assignment, an $n$-th order Markov model is a function that constructs a string of text one letter at a time, using only knowledge of the most recent $n$ letters. You can think of it as a writer with a \"memory\" of $n$ letters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports the functions defined in HW2.py \n",
    "\n",
    "from HW2 import count_characters, count_ngrams, markov_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Our training text for this exercise comes from Jane Austen's novel *Emma*, which Professor Chodrow retrieved from the archives at ([Project Gutenberg](https://www.gutenberg.org/files/158/158-h/158-h.htm#link2H_4_0001)). Intuitively, we are going to write a program that \"writes like Jane Austen,\" albeit in a very limited sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('emma-full.txt', 'r') as f:\n",
    "    s = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Define `count_characters` in HW2.py\n",
    "\n",
    "Write a function called `count_characters` that counts the number of times each character appears in a user-supplied string `s`. Your function should loop over each element of the string, and sequentually update a `dict` whose keys are characters and whose values are the number of occurrences seen so far.  Your function should then return this dictionary. \n",
    "\n",
    "You may know of other ways to achieve the same result. However, you are encouraged to use the loop approach, since this will generalize to the next exercise.\n",
    "\n",
    "*Note: While the construct `for character in s:` will work for this exercise, it will not generalize to the next one. Consider using `for i in range(len(s)):` instead.* \n",
    "\n",
    "### Example usage: \n",
    "\n",
    "```python\n",
    "count_characters(\"Torto ise!\")\n",
    "{'T': 1, 't' : 1, 'o' : 2, 'r' : 1, 'i' : 1, 's' : 1, 'e' : 1, ' ': 1, '!': 1}\n",
    "```\n",
    "\n",
    "***Hint***: Yes, you did a problem very similar to this one on HW1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T': 1, 'o': 2, 'r': 1, 't': 1, ' ': 1, 'i': 1, 's': 1, 'e': 1, '!': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing count_characters()\n",
    "\n",
    "count_characters(\"Torto ise!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 647,\n",
       " 'H': 1740,\n",
       " 'A': 708,\n",
       " 'P': 257,\n",
       " 'T': 1132,\n",
       " 'E': 1501,\n",
       " 'R': 215,\n",
       " ' ': 155119,\n",
       " 'I': 4013,\n",
       " '\\n': 4711,\n",
       " 'm': 17907,\n",
       " 'a': 53664,\n",
       " 'W': 1355,\n",
       " 'o': 52894,\n",
       " 'd': 28329,\n",
       " 'h': 40827,\n",
       " 'u': 20606,\n",
       " 's': 41556,\n",
       " 'e': 84502,\n",
       " ',': 12020,\n",
       " 'n': 46986,\n",
       " 'c': 14815,\n",
       " 'l': 27537,\n",
       " 'v': 7645,\n",
       " 'r': 40699,\n",
       " 'i': 42586,\n",
       " 'w': 14933,\n",
       " 't': 58067,\n",
       " 'f': 14598,\n",
       " 'b': 10532,\n",
       " 'p': 10284,\n",
       " 'y': 15268,\n",
       " 'g': 13525,\n",
       " 'x': 1346,\n",
       " ';': 2353,\n",
       " '-': 574,\n",
       " '.': 8881,\n",
       " 'S': 951,\n",
       " 'q': 895,\n",
       " '’': 1114,\n",
       " 'M': 2795,\n",
       " 'B': 598,\n",
       " 'j': 688,\n",
       " 'k': 4351,\n",
       " '—': 3102,\n",
       " ':': 174,\n",
       " '?': 621,\n",
       " '(': 107,\n",
       " ')': 107,\n",
       " 'L': 133,\n",
       " 'O': 304,\n",
       " 'N': 300,\n",
       " '“': 2099,\n",
       " '!': 1063,\n",
       " '”': 2090,\n",
       " 'J': 432,\n",
       " 'Y': 438,\n",
       " 'K': 412,\n",
       " 'D': 253,\n",
       " '‘': 112,\n",
       " 'z': 174,\n",
       " 'F': 541,\n",
       " 'G': 147,\n",
       " 'U': 39,\n",
       " 'V': 101,\n",
       " 'Q': 15,\n",
       " '8': 3,\n",
       " '2': 5,\n",
       " '3': 1,\n",
       " 'ï': 4,\n",
       " 'é': 5,\n",
       " 'X': 32,\n",
       " '4': 1,\n",
       " '&': 3,\n",
       " 'ê': 8,\n",
       " 'à': 4,\n",
       " '7': 1,\n",
       " '1': 2,\n",
       " '0': 8,\n",
       " '[': 1,\n",
       " ']': 1,\n",
       " '6': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing count_characters() function here \n",
    "\n",
    "count_characters(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many times does 't' appear in Emma? How about '!'?\n",
    "\n",
    "How many different types of characters are in this dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58067"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of times 't' appears\n",
    "\n",
    "emma_dictionary = count_characters(s)\n",
    "\n",
    "emma_dictionary['t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1063"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of times '!' appears\n",
    "\n",
    "emma_dictionary['!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of different characters \n",
    "\n",
    "len(emma_dictionary.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Define `count_ngrams` in HW2.py\n",
    "\n",
    "An `n`-*gram* is a sequence of `n` letters. For example, `bol` and `old` are the two 3-grams that occur in the string `bold`.\n",
    "\n",
    "Write a function called `count_ngrams` that counts the number of times each `n`-gram occurs in a string, with `n` specified by the user and with default value `n = 1`. Your function should return the dictionary. You should be able to do this by making only a small modification to `count_characters`. \n",
    "\n",
    "### Example usage: \n",
    "\n",
    "```python\n",
    "count_ngrams(\"tortoise\", n = 2)\n",
    "```\n",
    "```\n",
    "{'to': 2, 'or': 1, 'rt': 1, 'oi': 1, 'is': 1, 'se': 1} # output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 2, 'or': 1, 'rt': 1, 'oi': 1, 'is': 1, 'se': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing count_ngrams() function\n",
    "\n",
    "count_ngrams(\"tortoise\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CH': 58,\n",
       " 'HA': 56,\n",
       " 'AP': 55,\n",
       " 'PT': 55,\n",
       " 'TE': 55,\n",
       " 'ER': 55,\n",
       " 'R ': 56,\n",
       " ' I': 3085,\n",
       " 'I\\n': 38,\n",
       " '\\n\\n': 2316,\n",
       " '\\nE': 141,\n",
       " 'Em': 865,\n",
       " 'mm': 1173,\n",
       " 'ma': 3055,\n",
       " 'a ': 3661,\n",
       " ' W': 1097,\n",
       " 'Wo': 328,\n",
       " 'oo': 2145,\n",
       " 'od': 1311,\n",
       " 'dh': 324,\n",
       " 'ho': 3370,\n",
       " 'ou': 8439,\n",
       " 'us': 2611,\n",
       " 'se': 4852,\n",
       " 'e,': 2118,\n",
       " ', ': 11349,\n",
       " ' h': 12100,\n",
       " 'ha': 7723,\n",
       " 'an': 10801,\n",
       " 'nd': 7913,\n",
       " 'ds': 479,\n",
       " 'so': 2467,\n",
       " 'om': 2937,\n",
       " 'me': 4124,\n",
       " ' c': 5245,\n",
       " 'cl': 395,\n",
       " 'le': 4443,\n",
       " 'ev': 1842,\n",
       " 've': 6139,\n",
       " 'er': 13445,\n",
       " 'r,': 1069,\n",
       " ' a': 16999,\n",
       " 'd ': 15409,\n",
       " ' r': 2525,\n",
       " 'ri': 2888,\n",
       " 'ic': 1559,\n",
       " 'ch': 2881,\n",
       " 'h,': 253,\n",
       " ' w': 10466,\n",
       " 'wi': 2599,\n",
       " 'it': 6297,\n",
       " 'th': 14815,\n",
       " 'h ': 3665,\n",
       " 'co': 3538,\n",
       " 'mf': 127,\n",
       " 'fo': 2517,\n",
       " 'or': 5089,\n",
       " 'rt': 1883,\n",
       " 'ta': 1919,\n",
       " 'ab': 1225,\n",
       " 'bl': 1303,\n",
       " 'e ': 24757,\n",
       " 'ap': 964,\n",
       " 'pp': 913,\n",
       " 'py': 156,\n",
       " 'y ': 9330,\n",
       " ' d': 4265,\n",
       " 'di': 1795,\n",
       " 'is': 5368,\n",
       " 'sp': 921,\n",
       " 'po': 1249,\n",
       " 'os': 1284,\n",
       " 'si': 2127,\n",
       " 'ti': 3766,\n",
       " 'io': 2327,\n",
       " 'on': 7478,\n",
       " 'n,': 1084,\n",
       " ' s': 11089,\n",
       " 'ee': 2747,\n",
       " 'em': 1542,\n",
       " 'ed': 5863,\n",
       " ' t': 18602,\n",
       " 'to': 7198,\n",
       " 'o ': 8064,\n",
       " ' u': 1320,\n",
       " 'un': 1589,\n",
       " 'ni': 1383,\n",
       " 'te': 4668,\n",
       " ' o': 8508,\n",
       " 'of': 4665,\n",
       " 'f ': 5176,\n",
       " 'he': 17029,\n",
       " ' b': 7151,\n",
       " 'be': 4916,\n",
       " 'es': 4884,\n",
       " 'st': 4634,\n",
       " 't ': 15866,\n",
       " 'ss': 2344,\n",
       " 'in': 12243,\n",
       " 'ng': 6334,\n",
       " 'gs': 266,\n",
       " 's ': 12356,\n",
       " ' e': 3067,\n",
       " 'ex': 850,\n",
       " 'xi': 119,\n",
       " 'en': 6657,\n",
       " 'nc': 1756,\n",
       " 'ce': 2531,\n",
       " 'e;': 449,\n",
       " '; ': 2199,\n",
       " 'ad': 2979,\n",
       " ' l': 2927,\n",
       " 'li': 2605,\n",
       " 'iv': 910,\n",
       " ' n': 4532,\n",
       " 'ne': 3870,\n",
       " 'ea': 4245,\n",
       " 'ar': 5201,\n",
       " 'rl': 367,\n",
       " 'ly': 2824,\n",
       " 'tw': 310,\n",
       " 'we': 2067,\n",
       " 'nt': 3724,\n",
       " 'ty': 848,\n",
       " 'y-': 34,\n",
       " '-o': 16,\n",
       " ' y': 2538,\n",
       " 'ye': 442,\n",
       " 'rs': 2394,\n",
       " ' i': 7821,\n",
       " 'n ': 9065,\n",
       " 'wo': 1614,\n",
       " 'ld': 2731,\n",
       " ' v': 1571,\n",
       " 'ry': 2482,\n",
       " 'tt': 1446,\n",
       " 'tl': 1342,\n",
       " 'tr': 1009,\n",
       " 're': 8889,\n",
       " 'r ': 8521,\n",
       " 'x ': 152,\n",
       " 'r.': 1752,\n",
       " '.\\n': 727,\n",
       " '\\nS': 96,\n",
       " 'Sh': 584,\n",
       " 'wa': 3727,\n",
       " 'as': 5692,\n",
       " 'yo': 2363,\n",
       " 'ge': 1556,\n",
       " 'da': 848,\n",
       " 'au': 469,\n",
       " 'ug': 1037,\n",
       " 'gh': 2419,\n",
       " 'ht': 1696,\n",
       " ' m': 6449,\n",
       " 'mo': 1679,\n",
       " 'af': 459,\n",
       " 'ff': 613,\n",
       " 'fe': 1461,\n",
       " 'ec': 1717,\n",
       " 'ct': 1371,\n",
       " 'na': 616,\n",
       " 'at': 6876,\n",
       " 'du': 310,\n",
       " 'ul': 2866,\n",
       " 'lg': 35,\n",
       " ' f': 4936,\n",
       " 'fa': 1153,\n",
       " 'r;': 190,\n",
       " 'd,': 1325,\n",
       " 'ns': 1462,\n",
       " 'eq': 197,\n",
       " 'qu': 895,\n",
       " 'ue': 441,\n",
       " 'r’': 116,\n",
       " '’s': 931,\n",
       " 'rr': 1336,\n",
       " 'ia': 485,\n",
       " 'ag': 1057,\n",
       " 'mi': 1609,\n",
       " 'hi': 5323,\n",
       " 'fr': 1021,\n",
       " 'ro': 2292,\n",
       " 'm ': 1991,\n",
       " ' p': 3781,\n",
       " 'pe': 2162,\n",
       " 'd.': 692,\n",
       " '. ': 6176,\n",
       " ' H': 1320,\n",
       " 'He': 586,\n",
       " 'ot': 3527,\n",
       " 'ie': 2271,\n",
       " 'lo': 1442,\n",
       " 'g ': 4443,\n",
       " 'go': 812,\n",
       " 'av': 1846,\n",
       " 'mb': 205,\n",
       " 'br': 337,\n",
       " 'ra': 1998,\n",
       " 'ca': 1427,\n",
       " 's;': 221,\n",
       " 'pl': 1273,\n",
       " 'la': 1557,\n",
       " 'ac': 1276,\n",
       " 'su': 1976,\n",
       " 'up': 708,\n",
       " 'by': 577,\n",
       " 'xc': 230,\n",
       " 'el': 3549,\n",
       " 'll': 4373,\n",
       " ' g': 2323,\n",
       " 'ov': 663,\n",
       " 'rn': 532,\n",
       " 's,': 1396,\n",
       " 'wh': 2187,\n",
       " 'al': 3865,\n",
       " 'sh': 3263,\n",
       " 'n.': 632,\n",
       " 'Si': 11,\n",
       " 'ix': 124,\n",
       " 'xt': 210,\n",
       " ' M': 2448,\n",
       " 'Mi': 623,\n",
       " ' T': 641,\n",
       " 'Ta': 54,\n",
       " 'ay': 1792,\n",
       " 'yl': 91,\n",
       " 'Mr': 1855,\n",
       " 'e’': 101,\n",
       " 'am': 1331,\n",
       " 'il': 2186,\n",
       " 'y,': 1018,\n",
       " 'bo': 838,\n",
       " 'bu': 1412,\n",
       " 'ut': 2719,\n",
       " 'pa': 1216,\n",
       " 'cu': 537,\n",
       " ' E': 1235,\n",
       " 'a.': 79,\n",
       " ' B': 439,\n",
       " 'Be': 39,\n",
       " 'et': 2594,\n",
       " 'im': 1925,\n",
       " 'cy': 129,\n",
       " 's.': 1355,\n",
       " 'Ev': 51,\n",
       " 'ef': 696,\n",
       " 'ol': 1007,\n",
       " 'no': 4557,\n",
       " 'l ': 3300,\n",
       " 'fi': 1059,\n",
       " 'dn': 90,\n",
       " 'mp': 895,\n",
       " 'rd': 927,\n",
       " 'dl': 234,\n",
       " 'ow': 2407,\n",
       " 'ny': 890,\n",
       " 'ai': 2139,\n",
       " 't;': 247,\n",
       " 'do': 1361,\n",
       " 'w ': 1364,\n",
       " 'ei': 1055,\n",
       " 'aw': 433,\n",
       " 'ey': 1188,\n",
       " 'vi': 929,\n",
       " 'og': 142,\n",
       " 'mu': 1210,\n",
       " 'tu': 881,\n",
       " 'ua': 612,\n",
       " 'oi': 469,\n",
       " ' j': 376,\n",
       " 'ju': 318,\n",
       " 'ik': 353,\n",
       " 'ke': 1329,\n",
       " 'd;': 252,\n",
       " 'ig': 1695,\n",
       " 'hl': 49,\n",
       " 'ud': 284,\n",
       " 'dg': 176,\n",
       " 'gm': 37,\n",
       " 't,': 1258,\n",
       " 'ir': 1713,\n",
       " 'fl': 158,\n",
       " 'wn': 579,\n",
       " '\\nT': 174,\n",
       " 'Th': 911,\n",
       " 'ls': 341,\n",
       " 'de': 3156,\n",
       " 'a’': 110,\n",
       " 'uc': 1287,\n",
       " 'nk': 817,\n",
       " 'k ': 1204,\n",
       " 'lf': 763,\n",
       " 'f;': 57,\n",
       " 'sa': 1857,\n",
       " 'dv': 94,\n",
       " 'va': 297,\n",
       " 'hr': 225,\n",
       " 'oy': 142,\n",
       " 'nj': 82,\n",
       " 'jo': 159,\n",
       " 'ym': 69,\n",
       " 'ts': 616,\n",
       " 'pr': 1529,\n",
       " 'np': 34,\n",
       " 'rc': 506,\n",
       " 'id': 1673,\n",
       " 'sf': 118,\n",
       " 'So': 95,\n",
       " 'e—': 287,\n",
       " '—a': 389,\n",
       " 'w—': 21,\n",
       " '—b': 188,\n",
       " 'gr': 933,\n",
       " 'sc': 366,\n",
       " 'ci': 713,\n",
       " 'sn': 67,\n",
       " '.—': 724,\n",
       " '—M': 93,\n",
       " 'It': 405,\n",
       " 'f.': 156,\n",
       " 'dd': 257,\n",
       " 'g-': 51,\n",
       " '-d': 50,\n",
       " 'ur': 3024,\n",
       " 'nf': 256,\n",
       " 'fu': 482,\n",
       " 'nu': 201,\n",
       " 'e.': 1342,\n",
       " 'e-': 72,\n",
       " '-p': 33,\n",
       " 'eo': 116,\n",
       " 'op': 767,\n",
       " 'ft': 416,\n",
       " 'g.': 263,\n",
       " 'ms': 348,\n",
       " 'sl': 162,\n",
       " 'ep': 650,\n",
       " 'p ': 296,\n",
       " 'nn': 485,\n",
       " 'l,': 445,\n",
       " 'nl': 505,\n",
       " 't.': 835,\n",
       " 'pi': 571,\n",
       " 'We': 656,\n",
       " 'pt': 318,\n",
       " 'sy': 104,\n",
       " 'ui': 619,\n",
       " 'f-': 37,\n",
       " 'yi': 225,\n",
       " 'g,': 412,\n",
       " 'ip': 125,\n",
       " 'lw': 238,\n",
       " 'ys': 500,\n",
       " 'tc': 149,\n",
       " 'h;': 47,\n",
       " 'ck': 386,\n",
       " 'g’': 7,\n",
       " 'rk': 128,\n",
       " 'lt': 778,\n",
       " 'y.': 601,\n",
       " ' S': 672,\n",
       " ' k': 805,\n",
       " 'ki': 644,\n",
       " 's—': 175,\n",
       " '—t': 151,\n",
       " '—h': 81,\n",
       " 'd—': 179,\n",
       " 'vo': 251,\n",
       " 'h—': 36,\n",
       " 'ln': 33,\n",
       " ' A': 381,\n",
       " 'A ': 123,\n",
       " 'rg': 177,\n",
       " 'eb': 47,\n",
       " 'bt': 155,\n",
       " 'rf': 456,\n",
       " 'nr': 53,\n",
       " 'rv': 249,\n",
       " 'Is': 89,\n",
       " 'ew': 468,\n",
       " 'd:': 18,\n",
       " ': ': 128,\n",
       " 'l-': 53,\n",
       " '-i': 19,\n",
       " 'rm': 429,\n",
       " 'kn': 634,\n",
       " 'f,': 194,\n",
       " '—o': 60,\n",
       " 'ak': 766,\n",
       " '\\nH': 129,\n",
       " 'Ho': 131,\n",
       " 'e?': 123,\n",
       " '?—': 202,\n",
       " '—I': 343,\n",
       " 'ru': 404,\n",
       " 'm;': 75,\n",
       " 'if': 871,\n",
       " 'm,': 283,\n",
       " 'c,': 10,\n",
       " 'uf': 84,\n",
       " 'nv': 260,\n",
       " 'yf': 11,\n",
       " 'l.': 250,\n",
       " ' (': 85,\n",
       " '(a': 14,\n",
       " 'y)': 9,\n",
       " ') ': 76,\n",
       " 'cr': 383,\n",
       " 'bi': 138,\n",
       " 'dy': 495,\n",
       " 'yw': 19,\n",
       " ' L': 110,\n",
       " 'Lo': 58,\n",
       " ' O': 105,\n",
       " 'Oc': 4,\n",
       " 'ob': 492,\n",
       " ' N': 130,\n",
       " 'No': 256,\n",
       " 'gg': 53,\n",
       " 'gl': 224,\n",
       " 'Ha': 749,\n",
       " 'tf': 238,\n",
       " ' C': 548,\n",
       " 'Ch': 259,\n",
       " 'tm': 67,\n",
       " 'hu': 479,\n",
       " 'sb': 39,\n",
       " 'ba': 402,\n",
       " 'dr': 324,\n",
       " 'gi': 742,\n",
       " 'oc': 284,\n",
       " 'ga': 724,\n",
       " 'Hi': 205,\n",
       " 'hb': 165,\n",
       " 'pu': 208,\n",
       " 'lm': 121,\n",
       " 'ub': 370,\n",
       " 'bb': 52,\n",
       " 'Al': 21,\n",
       " 'ok': 493,\n",
       " 'm.': 235,\n",
       " 'cq': 117,\n",
       " 'cc': 328,\n",
       " 'eu': 8,\n",
       " 'u ': 1688,\n",
       " 'ib': 329,\n",
       " 'o,': 274,\n",
       " 'Ma': 160,\n",
       " 'o;': 57,\n",
       " 'hn': 101,\n",
       " 'sm': 194,\n",
       " 'xa': 88,\n",
       " ',\\n': 126,\n",
       " '\\n“': 1410,\n",
       " '“P': 28,\n",
       " 'Po': 31,\n",
       " 'r!': 61,\n",
       " '!—': 342,\n",
       " 'I ': 3149,\n",
       " 'Wh': 247,\n",
       " '!”': 160,\n",
       " '”\\n': 1394,\n",
       " '“I': 431,\n",
       " 'u,': 146,\n",
       " 'a;': 38,\n",
       " 'd-': 99,\n",
       " '-h': 47,\n",
       " 'um': 318,\n",
       " ';—': 129,\n",
       " 'my': 732,\n",
       " 'n?': 70,\n",
       " '?”': 238,\n",
       " '“A': 133,\n",
       " 'n!': 61,\n",
       " '—B': 67,\n",
       " 'Bu': 295,\n",
       " '? ': 165,\n",
       " '—A': 76,\n",
       " 'An': 254,\n",
       " '.”': 1159,\n",
       " '“H': 103,\n",
       " 's!': 87,\n",
       " '—W': 82,\n",
       " 'g!': 29,\n",
       " '! ': 527,\n",
       " 'eg': 446,\n",
       " 'n;': 238,\n",
       " '“M': 119,\n",
       " 'My': 112,\n",
       " 'r?': 51,\n",
       " ' R': 148,\n",
       " 'Ra': 92,\n",
       " 'lk': 352,\n",
       " '“N': 106,\n",
       " 'a,': 244,\n",
       " '“T': 136,\n",
       " 'e!': 169,\n",
       " ' J': 393,\n",
       " 'Ja': 324,\n",
       " 'y;': 226,\n",
       " 't?': 66,\n",
       " 'n’': 208,\n",
       " ' Y': 206,\n",
       " 'Yo': 346,\n",
       " 'lr': 60,\n",
       " 'ah': 6,\n",
       " 'r—': 127,\n",
       " '—J': 13,\n",
       " 'u!': 11,\n",
       " 'lu': 325,\n",
       " 'ky': 16,\n",
       " 't:': 16,\n",
       " '-s': 25,\n",
       " 'l;': 85,\n",
       " 'sk': 133,\n",
       " 'ks': 141,\n",
       " 'k,': 128,\n",
       " 'bs': 177,\n",
       " 'oe': 151,\n",
       " 'w,': 187,\n",
       " 'xe': 82,\n",
       " 'lp': 57,\n",
       " 'kg': 4,\n",
       " 'n-': 33,\n",
       " '-t': 56,\n",
       " 'rw': 106,\n",
       " '\\nM': 112,\n",
       " ' K': 405,\n",
       " 'Kn': 396,\n",
       " 't-': 47,\n",
       " '-a': 29,\n",
       " 'lc': 36,\n",
       " 's’': 46,\n",
       " '’ ': 95,\n",
       " 'Br': 35,\n",
       " 'sw': 162,\n",
       " 'Sq': 11,\n",
       " 'nq': 59,\n",
       " ' “': 568,\n",
       " '“p': 7,\n",
       " 'a”': 1,\n",
       " '” ': 610,\n",
       " 'k.': 67,\n",
       " '“B': 65,\n",
       " '“D': 37,\n",
       " 'Di': 73,\n",
       " '“W': 141,\n",
       " 'l!': 40,\n",
       " ' q': 484,\n",
       " 'rp': 137,\n",
       " 'df': 27,\n",
       " 'kf': 20,\n",
       " 'By': 13,\n",
       " 'eh': 129,\n",
       " 'Ah': 46,\n",
       " 'h!': 237,\n",
       " ' ’': 1,\n",
       " '’T': 2,\n",
       " 'Ti': 17,\n",
       " ' ‘': 91,\n",
       " '‘p': 3,\n",
       " '.’': 45,\n",
       " 'At': 34,\n",
       " 'o.': 124,\n",
       " '“E': 22,\n",
       " 'Es': 2,\n",
       " ',”': 436,\n",
       " 'h.': 143,\n",
       " 'a!': 13,\n",
       " 'u.': 117,\n",
       " 'Oh': 185,\n",
       " 'o!': 24,\n",
       " '—i': 84,\n",
       " 'm:': 7,\n",
       " 'ws': 123,\n",
       " '“b': 32,\n",
       " '—“': 121,\n",
       " '“y': 16,\n",
       " 'g;': 89,\n",
       " 's:': 27,\n",
       " 'De': 43,\n",
       " '“a': 49,\n",
       " ' P': 149,\n",
       " 'Pr': 23,\n",
       " 'd!': 114,\n",
       " 'w!': 5,\n",
       " '—E': 39,\n",
       " 'l—': 52,\n",
       " 'mn': 24,\n",
       " 'bj': 179,\n",
       " 'je': 208,\n",
       " 'y—': 103,\n",
       " 'o—': 58,\n",
       " 'oa': 138,\n",
       " 'dw': 26,\n",
       " 'La': 30,\n",
       " 'iz': 112,\n",
       " 'zz': 8,\n",
       " 'zl': 11,\n",
       " ' F': 501,\n",
       " 'Fa': 248,\n",
       " 'l’': 42,\n",
       " 'h-': 8,\n",
       " '-m': 48,\n",
       " '‘s': 2,\n",
       " ',’': 34,\n",
       " '’”': 13,\n",
       " '“S': 60,\n",
       " 'Su': 85,\n",
       " 'hy': 98,\n",
       " 'y’': 94,\n",
       " '‘I': 16,\n",
       " 's?': 49,\n",
       " 'f?': 12,\n",
       " 'gu': 216,\n",
       " 'iu': 12,\n",
       " 'ph': 61,\n",
       " '—f': 56,\n",
       " 'o-': 58,\n",
       " '-n': 15,\n",
       " 'If': 110,\n",
       " 'ej': 25,\n",
       " '“O': 129,\n",
       " 'On': 69,\n",
       " 'El': 420,\n",
       " ',—': 41,\n",
       " 'm—': 40,\n",
       " 'm!': 25,\n",
       " 'Wi': 90,\n",
       " 'In': 105,\n",
       " ' D': 185,\n",
       " '\\nC': 61,\n",
       " 'II': 40,\n",
       " 'Ca': 103,\n",
       " 'ze': 125,\n",
       " '-e': 8,\n",
       " '—w': 101,\n",
       " 'ux': 8,\n",
       " 'xu': 16,\n",
       " 'En': 65,\n",
       " 'e:': 27,\n",
       " 'az': 29,\n",
       " 'zi': 7,\n",
       " 'Fr': 223,\n",
       " 'xp': 231,\n",
       " 'r-': 47,\n",
       " '-f': 16,\n",
       " 'ek': 77,\n",
       " '\\nA': 54,\n",
       " '—e': 37,\n",
       " 'dj': 6,\n",
       " '\\nI': 63,\n",
       " 'yr': 1,\n",
       " 'c ': 42,\n",
       " 'nh': 32,\n",
       " '-j': 6,\n",
       " '\\nN': 12,\n",
       " 'Pe': 109,\n",
       " 'Ba': 179,\n",
       " 'gt': 28,\n",
       " 'wr': 169,\n",
       " 'Fo': 52,\n",
       " 'i,': 1,\n",
       " 'gy': 13,\n",
       " 'n—': 108,\n",
       " '—n': 63,\n",
       " 'ih': 3,\n",
       " 'wf': 7,\n",
       " '-c': 24,\n",
       " 'p.': 29,\n",
       " 'nw': 90,\n",
       " 'wl': 76,\n",
       " '(t': 12,\n",
       " 'n)': 4,\n",
       " '—p': 14,\n",
       " 'rh': 121,\n",
       " 'ps': 144,\n",
       " 'Do': 124,\n",
       " 'Ab': 41,\n",
       " '\\nR': 1,\n",
       " 'Re': 13,\n",
       " '-r': 43,\n",
       " 'Af': 21,\n",
       " ' G': 127,\n",
       " 'Go': 92,\n",
       " 'ml': 25,\n",
       " '-w': 26,\n",
       " 'Sc': 2,\n",
       " 'hm': 91,\n",
       " 'Bo': 25,\n",
       " 'lv': 125,\n",
       " 'd’': 74,\n",
       " 'ko': 6,\n",
       " 'lb': 8,\n",
       " 'a-': 4,\n",
       " '-v': 2,\n",
       " 'As': 55,\n",
       " 'Sm': 102,\n",
       " '-b': 36,\n",
       " 'dm': 115,\n",
       " 'p,': 50,\n",
       " 'tn': 66,\n",
       " 'ka': 19,\n",
       " 'h’': 12,\n",
       " 'g—': 66,\n",
       " 'k—': 16,\n",
       " '—v': 16,\n",
       " '—s': 111,\n",
       " '\\nU': 6,\n",
       " 'Up': 26,\n",
       " 'y:': 9,\n",
       " ':\\n': 6,\n",
       " 'Se': 26,\n",
       " 't—': 147,\n",
       " 'Ou': 10,\n",
       " '-g': 9,\n",
       " 't!': 87,\n",
       " '!\\n': 23,\n",
       " 'IV': 6,\n",
       " 'V\\n': 12,\n",
       " ' Q': 8,\n",
       " 'Qu': 15,\n",
       " 'gn': 81,\n",
       " 'Tw': 7,\n",
       " '-M': 7,\n",
       " 'hs': 44,\n",
       " 'hf': 7,\n",
       " '“t': 57,\n",
       " 'w;': 26,\n",
       " 'a:': 4,\n",
       " ':—': 33,\n",
       " 'oz': 7,\n",
       " '\\nF': 14,\n",
       " '\\nW': 31,\n",
       " ',)': 32,\n",
       " '“Y': 167,\n",
       " 'Na': 23,\n",
       " 'Ri': 16,\n",
       " 'd?': 35,\n",
       " 'Ag': 2,\n",
       " 'Ex': 21,\n",
       " ' V': 36,\n",
       " 'Vi': 14,\n",
       " 'Wa': 23,\n",
       " 'Ro': 36,\n",
       " '—\\n': 44,\n",
       " 'w.': 90,\n",
       " 'm?': 23,\n",
       " 'Ki': 14,\n",
       " 'To': 59,\n",
       " ' 8': 1,\n",
       " '8t': 3,\n",
       " 'Ju': 17,\n",
       " 'hd': 4,\n",
       " ' 2': 5,\n",
       " '23': 1,\n",
       " '3r': 1,\n",
       " '—c': 24,\n",
       " 'Ye': 91,\n",
       " 'za': 19,\n",
       " 'vu': 10,\n",
       " 't’': 132,\n",
       " 'ya': 9,\n",
       " '—H': 123,\n",
       " '—r': 15,\n",
       " 'n:': 17,\n",
       " '“h': 13,\n",
       " 'w?': 11,\n",
       " 'k?': 10,\n",
       " 'wk': 37,\n",
       " 'kw': 19,\n",
       " 'nm': 17,\n",
       " '“C': 19,\n",
       " 'Ce': 13,\n",
       " 'Co': 179,\n",
       " 'sg': 21,\n",
       " 'rb': 38,\n",
       " 'b ': 9,\n",
       " 'k”': 1,\n",
       " '”—': 85,\n",
       " 'Ne': 19,\n",
       " 'y?': 43,\n",
       " 'h:': 5,\n",
       " '“o': 8,\n",
       " 'g?': 32,\n",
       " 'o?': 31,\n",
       " '—N': 42,\n",
       " 'x,': 63,\n",
       " '-u': 7,\n",
       " 'bm': 17,\n",
       " '—Y': 58,\n",
       " 'I,': 28,\n",
       " '“w': 27,\n",
       " 'uz': 7,\n",
       " '—T': 119,\n",
       " 'nx': 56,\n",
       " 'u?': 19,\n",
       " 'Ve': 52,\n",
       " 'y!': 62,\n",
       " 'oh': 99,\n",
       " '‘t': 6,\n",
       " ';’': 6,\n",
       " '“V': 32,\n",
       " 'Jo': 90,\n",
       " '(I': 3,\n",
       " 'd)': 8,\n",
       " '“v': 10,\n",
       " '\\nP': 9,\n",
       " 'Pa': 28,\n",
       " 'VI': 18,\n",
       " 'fs': 5,\n",
       " 'Sk': 1,\n",
       " '“G': 9,\n",
       " 'Gr': 38,\n",
       " '“d': 7,\n",
       " 'aï': 4,\n",
       " 'ïv': 4,\n",
       " 'té': 4,\n",
       " 'é,': 2,\n",
       " 'xq': 9,\n",
       " '“L': 7,\n",
       " 'Le': 31,\n",
       " '“i': 31,\n",
       " '\\nY': 2,\n",
       " 'a—': 18,\n",
       " '’t': 19,\n",
       " 'Ke': 1,\n",
       " '‘w': 4,\n",
       " '?’': 6,\n",
       " '-l': 37,\n",
       " 'cs': 6,\n",
       " 'Ge': 8,\n",
       " '—u': 3,\n",
       " '“m': 10,\n",
       " '—m': 30,\n",
       " '—(': 22,\n",
       " '(M': 3,\n",
       " 'e)': 14,\n",
       " ')—': 18,\n",
       " 'e”': 4,\n",
       " 'f—': 31,\n",
       " 'k;': 18,\n",
       " '—O': 48,\n",
       " 'é ': 1,\n",
       " '‘E': 3,\n",
       " 'r:': 15,\n",
       " 'ao': 25,\n",
       " '—”': 36,\n",
       " '“U': 13,\n",
       " 'I’': 1,\n",
       " '’d': 4,\n",
       " '“s': 12,\n",
       " '(r': 6,\n",
       " 'nb': 6,\n",
       " 'Ar': 9,\n",
       " '‘Y': 4,\n",
       " '‘N': 9,\n",
       " 'o’': 11,\n",
       " 'p—': 10,\n",
       " '—D': 25,\n",
       " 'u;': 14,\n",
       " 'vy': 17,\n",
       " ';”': 17,\n",
       " '—R': 4,\n",
       " 'g:': 9,\n",
       " '(e': 3,\n",
       " 'r)': 8,\n",
       " '—y': 22,\n",
       " '(w': 15,\n",
       " 'g)': 3,\n",
       " 'pm': 5,\n",
       " '(n': 5,\n",
       " 'w)': 2,\n",
       " '—S': 119,\n",
       " 'Va': 2,\n",
       " 'Me': 15,\n",
       " '(f': 6,\n",
       " 't)': 5,\n",
       " '“R': 4,\n",
       " 'oj': 5,\n",
       " 'fy': 33,\n",
       " '(s': 9,\n",
       " 's)': 11,\n",
       " 'Cl': 3,\n",
       " 'yt': 2,\n",
       " 'IX': 4,\n",
       " 'X\\n': 7,\n",
       " 'Pi': 2,\n",
       " '“K': 5,\n",
       " '-k': 2,\n",
       " '\\n ': 15,\n",
       " '  ': 63,\n",
       " 'l\\n': 1,\n",
       " 'e\\n': 1,\n",
       " '\\nm': 1,\n",
       " '\\nB': 24,\n",
       " '——': 7,\n",
       " 'AR': 2,\n",
       " 'RA': 1,\n",
       " 'AD': 2,\n",
       " 'DE': 2,\n",
       " 'E.': 12,\n",
       " ';\\n': 2,\n",
       " '\\nL': 4,\n",
       " '—‘': 18,\n",
       " '‘P': 1,\n",
       " 'Ap': 5,\n",
       " '’\\n': 2,\n",
       " 'Hu': 10,\n",
       " 'gd': 5,\n",
       " '?\\n': 9,\n",
       " '\\nO': 10,\n",
       " 'Or': 4,\n",
       " 'Gi': 8,\n",
       " ' —': 3,\n",
       " '—,': 2,\n",
       " 'p;': 9,\n",
       " '(c': 3,\n",
       " '‘T': 3,\n",
       " '—.': 5,\n",
       " '—C': 15,\n",
       " 'f!': 11,\n",
       " 'ae': 2,\n",
       " 'k!': 10,\n",
       " 'm-': 4,\n",
       " 'Tr': 8,\n",
       " '\\n—': 1,\n",
       " 'h?': 10,\n",
       " '(d': 2,\n",
       " 'Ay': 13,\n",
       " '‘W': 3,\n",
       " 'nz': 2,\n",
       " '\\nK': 2,\n",
       " 'k’': 13,\n",
       " 'Ga': 1,\n",
       " '—j': 7,\n",
       " 'Ea': 3,\n",
       " 'wy': 3,\n",
       " '—P': 15,\n",
       " '(i': 7,\n",
       " '28': 2,\n",
       " ' U': 12,\n",
       " 'Un': 9,\n",
       " 'a?': 8,\n",
       " '‘G': 3,\n",
       " 'dp': 4,\n",
       " '’c': 8,\n",
       " 'Of': 16,\n",
       " '—g': 10,\n",
       " '(l': 6,\n",
       " '),': 7,\n",
       " ' X': 28,\n",
       " 'c!': 1,\n",
       " 'ax': 243,\n",
       " 'x.': 32,\n",
       " 'tp': 3,\n",
       " 'St': 16,\n",
       " 'aj': 2,\n",
       " 'ja': 3,\n",
       " 'XI': 13,\n",
       " 'gf': 10,\n",
       " 'Ei': 3,\n",
       " '“J': 12,\n",
       " '— ': 21,\n",
       " 'bh': 3,\n",
       " '‘M': 10,\n",
       " '‘F': 2,\n",
       " 'F.': 3,\n",
       " 'C.': 2,\n",
       " '’—': 20,\n",
       " 'Te': 10,\n",
       " 'Li': 10,\n",
       " '’y': 5,\n",
       " 'cd': 1,\n",
       " 'uo': 9,\n",
       " 'Au': 8,\n",
       " 'kl': 39,\n",
       " 'm’': 3,\n",
       " 'x;': 7,\n",
       " 'x!': 9,\n",
       " 'pb': 78,\n",
       " 'Ph': 2,\n",
       " 'Cr': 29,\n",
       " 'w’': 6,\n",
       " 'yn': 2,\n",
       " '..': 31,\n",
       " '24': 1,\n",
       " '4t': 1,\n",
       " ' &': 3,\n",
       " '&c': 3,\n",
       " 'c.': 11,\n",
       " 'Mo': 12,\n",
       " 'Ac': 5,\n",
       " 'Mu': 11,\n",
       " 'Dr': 4,\n",
       " '“Q': 3,\n",
       " '’n': 1,\n",
       " 'p-': 4,\n",
       " ' z': 5,\n",
       " ...}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing count_ngrams() function\n",
    "\n",
    "count_ngrams(s, n = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many different types of 2-grams are in this dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding how many different types of 2-grams are in the emma text\n",
    "\n",
    "len(count_ngrams(s, 2).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Define `markov_text` in HW2.py\n",
    "\n",
    "Now we are going to use our `n`-grams to generate some fake text according to a Markov model. Here's how the Markov model of order `n` works: \n",
    "\n",
    "### A. Compute (`n`+1)-gram occurrence frequencies\n",
    "\n",
    "You have already done this in Problem 2!  \n",
    "\n",
    "### B. Starting `n`-gram\n",
    "\n",
    "The starting `n`-gram is the last `n` characters in the argument `seed`.\n",
    "\n",
    "### C. Generate Text\n",
    "\n",
    "Now we generate text one character at a time. To do so:\n",
    "\n",
    "1. Look at the most recent `n` characters in our generated text. Say that `n = 3` and the 3 most recent character are `the`. \n",
    "2. We then look at our list of `n+1`-grams, and focus on grams whose first `n` characters match. Examples matching `the` include `them`, `the `, `thei`, and so on. \n",
    "3. We pick a random one of these `n+1`-grams, weighted according to its number of occurrences. \n",
    "4. The final character of this new `n+1` gram is our next letter. \n",
    "\n",
    "For example, if there are 3 occurrences of `them`, 4 occurrences of `the `, and 1 occurrences of `thei` in the n-gram dictionary, then our next character is `m` with probabiliy 3/8, `[space]` with probability 1/2, and `i` with probability `1/8`. \n",
    "\n",
    "**Remember**: the ***3rd***-order model requires you to compute ***4***-grams. \n",
    "\n",
    "## What you should do\n",
    "\n",
    "Write a function `markov_text` that generates synthetic text according to an `n`-th order Markov model. It should have the following arguments: \n",
    "\n",
    "- `s`, the input string of real text. \n",
    "- `n`, the order of the model. \n",
    "- `length`, the size of the text to generate. Use a default value of 100. \n",
    "-  `seed`, the initial string that gets the Markov model started. I used `\"Emma Woodhouse\"` (the full name of the protagonist of the novel) as my `seed`, but any subset of `s` of length `n` or larger will work. \n",
    "\n",
    "It should return a string with the length of `len(seed) + length`.\n",
    "\n",
    "Demonstrate the output of your function for a couple different choices of the order `n`. \n",
    "\n",
    "\n",
    "## Expected Output\n",
    "\n",
    "Here are a few examples of the output of this function. Because of randomness, your results won't look exactly like this, but they should be qualitatively similar. \n",
    "\n",
    "```python\n",
    "markov_text(s, n = 2, length = 200, seed = \"Emma Woodhouse\")\n",
    "```\n",
    "```\n",
    "Emma Woodhouse ne goo thimser. John mile sawas amintrought will on I kink you kno but every sh inat he fing as sat buty aft from the it. She cousency ined, yount; ate nambery quirld diall yethery, yould hat earatte\n",
    "```\n",
    "```python\n",
    "markov_text(s, n = 4, length = 200, seed = \"Emma Woodhouse\")\n",
    "```\n",
    "\n",
    "```\n",
    "Emma Woodhouse!”—Emma, as love,            Kitty, only this person no infering ever, while, and tried very were no do be very friendly and into aid,    Man's me to loudness of Harriet's. Harriet belonger opinion an\n",
    "```\n",
    "\n",
    "```python\n",
    "markov_text(s, n = 10, length = 200, seed = \"Emma Woodhouse\")\n",
    "```\n",
    "\n",
    "```\n",
    "Emma Woodhouse's party could be acceptable to them, that if she ever were disposed to think of nothing but good. It will be an excellent charade remains, fit for any acquainted with the child was given up to them.\n",
    "```\n",
    "\n",
    "## Notes and Hints\n",
    "\n",
    "***Hint***: A good function for performing the random choice is the `choices()` function in the `random` module. You can use it like this: \n",
    "\n",
    "```python\n",
    "import random\n",
    "\n",
    "options = [\"One\", \"Two\", \"Three\"]\n",
    "weights = [1, 2, 3] # \"Two\" is twice as likely as \"One\", \"Three\" three times as likely. \n",
    "\n",
    "random.choices(options, weights) \n",
    "```\n",
    "\n",
    "```\n",
    "['One'] # output\n",
    "```\n",
    "\n",
    "The first and second arguments must be lists of equal length. Note also that the return value is a list -- if you want the value *in* the list, you need to get it out via indexing.  \n",
    "\n",
    "***Note***: For grading purposes, the `options` should be the possible `n+1`-grams in the order of first appeareance in the text. If you are working through the strings from beginning to end, you will not have issues with this, as dictionary keys are ordered. Please do NOT use [`random.seed()`](https://www.w3schools.com/python/ref_random_seed.asp) in your function -- the autograder code will do it. You are welcome to try it out in your notebook for reproducible results if you are interested. \n",
    "\n",
    "***Hint***: The first thing your function should do is call `count_ngrams` above to generate the required dictionary. Then, handle the logic described above in the main loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emma Woodhouse to withe welin he dery may, setund and be me ans. Mrs ver quishemen, ase. Theme mys one own wit whin and rearry elf, sainto—It papping to beed ned, ind factle for al, pok Mise.—Exculd movend sly coub'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing markov_text() function with order of 2\n",
    "\n",
    "markov_text(s, n = 2, length = 200, seed = \"Emma Woodhouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emma Woodhouse. But he cared for elegance him.”\\n\\nEmma, “now tell and her it mightless of life. It is very little prompt agreeable, somebody’s respect of matter:—Robert was rather country-dancing both of hint of the'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing markov_text() function with order of 4\n",
    "\n",
    "markov_text(s, n = 4, length = 200, seed = \"Emma Woodhouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emma Woodhouse, I may just as well. We shall have hoped to make the eighth, Jane Fairfax!” said Mrs. Elton, of the utmost; and all the high opinion of Harriet’s secret had not been for the friend was going to take '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing markov_text() function with order of 10\n",
    "\n",
    "markov_text(s, n = 10, length = 200, seed = \"Emma Woodhouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Using a `for`-loop, print the output of your function for `n` ranging from `1` to `10` (including 10).\n",
    "\n",
    "Then, write down a few observations. How does the generated text depend on `n`? How does the time required to generate the text depend on `n`? Do your best to explain each observation.  \n",
    "\n",
    "What do you think could happen if you were to repeat this assignment but in unit of words and not in unit of characters? For example, 2-grams would indicate two words, and not two characters.\n",
    "\n",
    "What heuristics would you consider adding to your model to improve its prediction performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output for order of 1 is: Emma Woodhoused werenofonk, Falith.”\n",
      "“Pert Yoansat nd hasulindhthe aneghinghe ghaceafomerr she ene pbematrd, d ad l thedo olen y, ltor winotly, amo hoton mucout blldhevemad It hemusue, I tot the he ane sed trp. che\n",
      "\n",
      "The output for order of 2 is: Emma Woodhouse hiss area fax’s admight begre was prou, appy been havery Jannot affinmake was. Mrst bet on par Mrs, stancep mys the ne th a com briss hents whoon. Perive red be whapplitelf-sitan be my himend her for\n",
      "\n",
      "The output for order of 3 is: Emma Woodhouse her, friends the fit in spirity, an had with.”\n",
      "\n",
      "“We as to seemed I, my she chan my from her find-hearlies out nicand the intenial it to charbour own lips, I am suppose of againly dress Smith a gened \n",
      "\n",
      "The output for order of 4 is: Emma Woodhouse,” said of the old own, whole on his hot a replied was not really impossible, the knew a life, which she the was as so;—and perior. It have not thing.—I can being the can alarm insisterday well. Graha\n",
      "\n",
      "The output for order of 5 is: Emma Woodhouse’s first blessing one amiss I can fast, was sad give to thing simplicity to be spoke as clever.\n",
      "\n",
      "“For so nerves till her how very body’s habit of my two—and he happy; and, but forwards Harriet. “Poor \n",
      "\n",
      "The output for order of 6 is: Emma Woodhouse, you were to increased with them into his daughter?—I dare too necessary. She was in possessed again how Frank Churchill was four-and-twenty—a pert you. What is, his inquire after breathing! so long,\n",
      "\n",
      "The output for order of 7 is: Emma Woodhouse, who had not open eagerness to Mr. Elton appear in the person I never look comfortable with speculations. We have never look as if he cannot be hazard with her mother, when it is but one in returned,\n",
      "\n",
      "The output for order of 8 is: Emma Woodhouse or Mr. Knightley and Mr. Knightley’s going on, that to him in her character,) she was quite ready. I only waiting, it appear to affix more meaning. She had had enough to shew them to be assured than \n",
      "\n",
      "The output for order of 9 is: Emma Woodhouse, our saucy looks—‘Mr. Knightley ‘no;’ and Miss Bickerton in the world.”\n",
      "\n",
      "“Indeed! but why so?—I can hardly believed must still use it. I assure you, my dear. With all due deference, and by only turne\n",
      "\n",
      "The output for order of 10 is: Emma Woodhouse,” he almost immediately ready, Emma did suspect that in the middle of the Eltons’ departure of their pleasure. When Mr. Cole on business from Emma. She will give you all the reproofs she could never \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run your markov_text here\n",
    "\n",
    "for n in range(1, 11):\n",
    "    print(f'The output for order of {n} is: {markov_text(s, n, length = 200, seed = \"Emma Woodhouse\")}')\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For value n = 1, the output seemed to be the most random and unreadable. There seemed to be no logic and it was \n",
    "# like reading nonsense. For value of n = 2, the output was very much like the previous one: nonsense. There appeared\n",
    "# to be fewer non-alphabetical characters, but there was still no logic. The output for value of n = 3 was similiar to\n",
    "# previous two, since nothing seemed to make sense. The output for n = 4 started to make a little bit of sense. There \n",
    "# were actual words within the string and didn't seem as random as the previous 3. For order of 5, the output became\n",
    "# even better. The non-alphabet characters didn't seem to just be placed randomly and felt like it was more purposeful. \n",
    "# For order of 6, the entire string seemed to be containing actual words. Even though there wasn't any meaning that could \n",
    "# be extracted from it, the words were still clear and readable. For n = 7, the words still seemed to be real but the \n",
    "# syntax still wasn't great. For n = 8, the surrounding words of the string seemed to be somewhat relatable to each other.\n",
    "# However, the entire string itself couldn't provide any sense of meaning or purpose. For n = 9, it was very much like the\n",
    "# output for 8: surrounding words are related but no general meaning is extracted. For n = 10, the output was very \n",
    "# close to the previous two. \n",
    "\n",
    "# Overall, it seemed like the generated text seemed to fit better with the seed word with a higher n value. \n",
    "# At the beginning, all the new characters just felt like gibberish, but as n increased the function seemed to produce\n",
    "# more accurate words and also ended up being relevant to the words that surrounded it. However, it doesn't seem\n",
    "# like the function imrproved in its syntax all that much. It ended better than at the beginning, but it still didn't\n",
    "# \"learn\" how to use the non-alphabetic characters. \n",
    "\n",
    "# The time that it took to return a result increased as n increased. It look less than a second for the \n",
    "# function with n = 4 to run, but took over 6 seconds for the function with n = 10 to run.  \n",
    "\n",
    "# If I were to repeat this assignment in units of words instead of characters, I think the function would perform \n",
    "# even better than it does currently. The function would encounter actual, meaningful words instead of character \n",
    "# subsets, so its prediction would end up being better. \n",
    "\n",
    "# To improve the predictions, I would do 2 things. First, I would use a larger text so the model has more information\n",
    "# to generate from. Perhaps having a larger text would help it learn when to properly use the non-alphabetic\n",
    "# characters. The second thing I would do is introduce some basic syntactical rules to the model. For example, adding '\"'\n",
    "# to the string would make it so the string would have to contain another '\"' within. Rules like this would make the \n",
    "# character generation better and would ideally make the performance better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "\n",
    "Try running your program with a different text! \n",
    "\n",
    "You can \n",
    "- find any movie script from https://imsdb.com/ or a book by Shakespeare, Hemingway, Beowulf, O.Henry, A.A. Milne, etc from https://www.gutenberg.org/\n",
    "- ctrl + a to select all text on the page\n",
    "- copy paste into a new `.txt` file. let's call it `book.txt`.\n",
    "- put `book.txt` in the same folder as emma-full.txt.\n",
    "- run the following code to read the file into variable `s`.\n",
    "```python\n",
    "with open('book.txt', 'r') as f:\n",
    "    s = f.read()\n",
    "```\n",
    "- run `markov_text` on `s` with appropriate parameters.\n",
    "\n",
    "Show your output here. Which parameters did you pick and why? Do you see any difference from when you ran the program with Emma? How so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"T'Challa inherited from the\\n            Further back . T'Challa sees the\\n               I would rather be the force and Panther bounds back and T'Challa, eyes closed, struggles to breathe.\\n\\n           T'CHALL\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run your new code\n",
    "\n",
    "with open('BLACK PANTHER.txt', 'r') as f:\n",
    "    new_s = f.read()\n",
    "\n",
    "markov_text(new_s, n = 8, length = 200, seed = \"T'Challa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the link to the transcript I used: https://imsdb.com/Movie%20Scripts/Black%20Panther%20Script.html\n",
    "\n",
    "# I picked the order to 8 because I wanted a relatively high number since I know that the model \n",
    "# will predict better with a higher value. I chose a length of 200 because it was the length specified\n",
    "# for the previous model and I think it a good number because the output isn't either too short or too long.\n",
    "# I picked the seed to be \"T'Challa\" because that is the name of the main character and so his name is \n",
    "# mentioned the most.\n",
    "\n",
    "# I noticed that the output for this was not nearly as good as what it was for the Emma text. I think the fact\n",
    "# that this is a movie script compared to a standard book text may have thrown the model off. Movie transcripts \n",
    "# have a different format than a book, which a model like this might have trouble handling. Move transcripts have\n",
    "# bold text on the top that tells you which character is speaking, has dialogue, and also descriptions about \n",
    "# actions that are happening in the environment during the dialogue. I doubt a simple model such as this would\n",
    "# be able to pick up on all of these details and differentiate between them. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
