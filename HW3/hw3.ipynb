{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f12b1551-7415-4080-b4a5-6f6768567f8a",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "### Name: Palash Raval\n",
    "### Collaborators: None\n",
    "\n",
    "Due date: May 26, 2025\n",
    "\n",
    "Submission instructions: \n",
    "- __Autograder will not be used for scoring, but you still need to submit the python file converted from this notebook (.py) and the notebook file (.ipynb) to the code submission window.__ \n",
    "To convert a Jupyter Notebook (`.ipynb`) to a regular Python script (`.py`):\n",
    "  - In Jupyter Notebook: File > Download as > Python (.py)\n",
    "  - In JupyterLab: File > Save and Export Notebook As... > Executable Script\n",
    "  - In VS Code Jupyter Notebook App: In the toolbar, there is an Export menu. Click on it, and select Python script.\n",
    "- Submit `hw3.ipynb` and `hw3.py` on Gradescope under the window \"Homework 3 - code\". Do **NOT** change the file name.\n",
    "- Convert this notebook into a pdf file and submit it on Gradescope under the window \"Homework 3 - PDF\". Make sure all your code and text outputs in the problems are visible. \n",
    "\n",
    "\n",
    "This homework requires a new package, `pyarrow`, which runs behind `duckdb`. Please make sure to install them in your `BIOSTAT203C-24S` environment:\n",
    "\n",
    "```bash\n",
    "conda activate BIOSTAT203C-25S\n",
    "conda install -c conda-forge pyarrow\n",
    "pip install polars\n",
    "```\n",
    "\n",
    "\n",
    "## Problem 1. \n",
    "\n",
    "Recall the simple random walk.  At each step, we flip a fair coin. If heads, we move \"forward\" one unit; if tails, we move \"backward.\" \n",
    "\n",
    "### (A).\n",
    "\n",
    "Way back in Homework 1, you wrote some code to simulate a random walk in Python. \n",
    "\n",
    "Start with this code. If you have since written random walk code that you prefer, you can use this instead. Regardless, take your code, modify it, and enclose it in a function `rw()`. This function should accept a single argument `n`, the length of the walk. The output should be a list giving the position of the random walker, starting with the position after the first step. For example, \n",
    "\n",
    "```python\n",
    "rw(5)\n",
    "[1, 2, 3, 2, 3]\n",
    "```\n",
    "\n",
    "Unlike in the HW1 problem, you should not use upper or lower bounds. The walk should always run for as long as the user-specified number of steps `n`. \n",
    "\n",
    "Use your function to print out the positions of a random walk of length `n = 10`. \n",
    "\n",
    "Don't forget a helpful docstring! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a905b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "070b708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function does a simple random walk. \n",
    "It takes in one input: n(an integer denoting the number of steps to take).\n",
    "The output for this function is a list that shows the overall position at each step with the\n",
    "list's length being the value of n.\n",
    "'''\n",
    "\n",
    "def rw(n):\n",
    "    step_list = []\n",
    "    starting_spot = 0\n",
    "    for step in range(n):\n",
    "        direction = random.choice([-1, 1])\n",
    "        starting_spot = starting_spot + direction\n",
    "        step_list.append(starting_spot)\n",
    "    \n",
    "    return(step_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d1f65bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2, -1, -2, -3, -2, -1, -2, -3, -4]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing rw() function with n value of 10\n",
    "\n",
    "rw(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678abaa8-a334-47e1-81f6-590724c0a75f",
   "metadata": {},
   "source": [
    "### (B). \n",
    "\n",
    "Now create a function called `rw2(n)`, where the argument `n` means the same thing that it did in Part A. Do so using `numpy` tools. Demonstrate your function as above, by creating a random walk of length 10. You can (and should) return your walk as a `numpy` array. \n",
    "\n",
    "**Requirements**: \n",
    "\n",
    "- No for-loops. \n",
    "- This function is simple enough to be implemented as a one-liner of fewer than 80 characters, using lambda notation. Even if you choose not to use lambda notation, the body of your function definition should be no more than three lines long. Importing `numpy` does not count as a line. \n",
    "- A docstring is required if and only if you take more than one line to define the function. \n",
    "\n",
    "**Hints**:\n",
    "\n",
    "- Check the documentation for `np.random.choice()`. \n",
    "- `np.cumsum()`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd383e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating function to get numpy array for simple walk \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def rw2(n):\n",
    "    return np.cumsum(np.random.choice([-1,1], n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83ccb1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  2,  3,  4,  3,  2,  1,  0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing rw2() function using n = 10 \n",
    "\n",
    "rw2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad5c360-3302-4375-a151-ab3a63ec5fa3",
   "metadata": {},
   "source": [
    "### (C).\n",
    "\n",
    "Use the `%timeit` magic macro to compare the runtime of `rw()` and `rw2()`. Test how each function does in computing a random walk of length `n = 10000`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92580fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.95 ms ± 7.32 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rw(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a7d03c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.6 µs ± 14 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit rw2(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbea2f6-1e39-415a-aa16-defe9ba79268",
   "metadata": {},
   "source": [
    "### (D). \n",
    "\n",
    "Write a few sentences in which you comment on (a) the performance of each function and (b) the ease of writing and reading each function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b34fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In terms of performance, rw2() was much faster than rw(). It took 1.95 ms for rw() to run\n",
    "#whereas, it only took rw2() 72.6 µs to run. For this problem, the speed doesn't seem to matter a whole lot \n",
    "#because this problem is not computationally extensive. However, it think this shows that it would be advantageous\n",
    "#to use numpy arrays whenever you are working with more extensive problems.\n",
    "\n",
    "\n",
    "#In terms of ease of writing and reading the two functions, I would say that the rw2() function is much \n",
    "#easier to read and write. It took only a couple lines to define the entire function, which is why I said\n",
    "#it would be easier to read and write. The rw() function is longer, so it would take longer to read and to write."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b5fcb-9c45-4a16-8642-1e47216ccbc4",
   "metadata": {},
   "source": [
    "### (E). \n",
    "\n",
    "\n",
    "In this problem, we will perform a `d`-dimensional random walk. There are many ways to define such a walk. Here's the definition we'll use for this problem: \n",
    "\n",
    "> At each timestep, the walker takes one random step forward or backward **in each of `d` directions.** \n",
    "\n",
    "For example, in a two-dimensional walk on a grid, in each timestep the walker would take a step either north or south, and then another step either east or west. Another way to think about is as the walker taking a single \"diagonal\" step either northeast, southeast, southwest, or northwest. \n",
    "\n",
    "Write a function called `rw_d(n,d)` that implements a `d`-dimensional random walk. `n` is again the number of steps that the walker should take, and `d` is the dimension of the walk. The output should be given as a `numpy` array of shape `(n,d)`, where the `k`th row of the array specifies the position of the walker after `k` steps. For example: \n",
    "\n",
    "```python\n",
    "P = rw_d(5, 3)\n",
    "P\n",
    "```\n",
    "```\n",
    "array([[-1, -1, -1],\n",
    "       [ 0, -2, -2],\n",
    "       [-1, -3, -3],\n",
    "       [-2, -2, -2],\n",
    "       [-1, -3, -1]])\n",
    "```\n",
    "\n",
    "In this example, the third row `P[2,:] = [-1, -3, -3]` gives the position of the walk after 3 steps. \n",
    "\n",
    "Demonstrate your function by generating a 3d walk with 5 steps, as shown in the example above. \n",
    "\n",
    "All the same requirements and hints from Part B apply in this problem as well. It should be possible to solve this problem by making only a few small modifications to your solution from Part B. If you are finding that this is not possible, you may want to either (a) read the documentation for the relevant `numpy` functions more closely or (b) reconsider your Part B approach. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b383552-1ec5-4bd1-9c7b-b67dc7fe67cb",
   "metadata": {},
   "source": [
    "### (F).\n",
    "\n",
    "In a few sentences, describe how you would have solved Part E without `numpy` tools. Take a guess as to how many lines it would have taken you to define the appropriate function. Based on your findings in Parts C and D, how would you expect its performance to compare to your `numpy`-based function from Part E? Which approach would your recommend? \n",
    "\n",
    "Note: while I obviously prefer the `numpy` approach, it is reasonable and valid to prefer the \"vanilla\" way instead. Either way, you should be ready to justify your preference on the basis of writeability, readability, and performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307e8e5-1278-4bba-b22f-bf7816eb43c8",
   "metadata": {},
   "source": [
    "### (G).\n",
    "\n",
    "Once you've implemented `rw_d()`, you can run the following code to generate a large random walk and visualize it. \n",
    "\n",
    "```python\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "W = rw_d(20000, 2)\n",
    "plt.plot(W[:,0], W[:,1])\n",
    "```\n",
    "\n",
    "You may be interested in looking at several other visualizations of multidimensional random walks [on Wikipedia](https://en.wikipedia.org/wiki/Random_walk). Your result in this part will not look exactly the same, but should look qualitatively fairly similar. \n",
    "\n",
    "You only need to show one plot. If you like, you might enjoy playing around with the plot settings. While `ax.plot()` is the normal method to use here, `ax.scatter()` with partially transparent points can also produce some intriguing images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def78985-0fc4-4ac7-a804-4debe01426b4",
   "metadata": {},
   "source": [
    "## Problem 2. Reading MIMIC-IV datafile\n",
    "In this exercise, we explore various tools for ingesting the [MIMIC-IV](https://mimic.mit.edu/docs/iv/) data introduced in BIOSTAT 203B, but we will do it in Python this time.\n",
    "\n",
    "Let's display the contents of MIMIC `hosp` and `icu` data folders: (if a cell starts with a `!`, the command is run in the shell.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1948eaab-6f54-482a-a0ca-b1fa36a38f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8859760\r\n",
      "-rw-r--r--  1 kose  staff    15516088 Jan  5  2023 admissions.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff      427468 Jan  5  2023 d_hcpcs.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff      859438 Jan  5  2023 d_icd_diagnoses.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff      578517 Jan  5  2023 d_icd_procedures.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff       12900 Jan  5  2023 d_labitems.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff    25070720 Jan  5  2023 diagnoses_icd.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff     7426955 Jan  5  2023 drgcodes.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff   508524623 Jan  5  2023 emar.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff   471096030 Jan  5  2023 emar_detail.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff     1767138 Jan  5  2023 hcpcsevents.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff        2907 May  2 11:03 index.html\r\n",
      "-rw-r--r--@ 1 kose  staff  1939088924 May  3 14:10 labevents.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff    96698496 Jan  5  2023 microbiologyevents.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff    36124944 Jan  5  2023 omr.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff     2312631 Jan  5  2023 patients.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff   398753125 Jan  5  2023 pharmacy.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff   498505135 Jan  5  2023 poe.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff    25477219 Jan  5  2023 poe_detail.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff   458817415 Jan  5  2023 prescriptions.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff     6027067 Jan  5  2023 procedures_icd.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff      122507 Jan  5  2023 provider.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff     6781247 Jan  5  2023 services.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff    36158338 Jan  5  2023 transfers.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ~/mimic/hosp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512dcc57-1024-4e42-a2f5-c028ee351d82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 6155976\r\n",
      "-rw-r--r--  1 kose  staff       35893 Jan  5  2023 caregiver.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff  2467761053 Jan  5  2023 chartevents.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff       57476 Jan  5  2023 d_items.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff    45721062 Jan  5  2023 datetimeevents.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff     2614571 Jan  5  2023 icustays.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff        1336 May  2 11:03 index.html\r\n",
      "-rw-r--r--  1 kose  staff   251962313 Jan  5  2023 ingredientevents.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff   324218488 Jan  5  2023 inputevents.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff    38747895 Jan  5  2023 outputevents.csv.gz\r\n",
      "-rw-r--r--  1 kose  staff    20717852 Jan  5  2023 procedureevents.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ~/mimic/icu/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9d704-df48-4dc8-a3d2-35747b75f2f8",
   "metadata": {},
   "source": [
    "### (A). Speed, memory, and data types\n",
    "\n",
    "Standard way to read a CSV file would be using the `read_csv` function of the `pandas` package. Let us check the speed of reading a moderate-sized compressed csv file, `admissions.csv.gz`. How much memory does the resulting data frame use?\n",
    "\n",
    "_Note:_ The runtime will be measured with `%%time` on the top of the code cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1491db4-c6ea-4ad1-8071-42c129cb08c3",
   "metadata": {},
   "source": [
    "### (B). User-supplied data types\n",
    "\n",
    "Re-ingest `admissions.csv.gz` by indicating appropriate column data types in [`pd.read_csv`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). Does the run time change? How much memory does the result dataframe use? (Hint: `dtype` and `parse_dates` arguments in `pd.read_csv`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d7ab0-adfb-406c-a009-86065a7f4ba1",
   "metadata": {},
   "source": [
    "## Problem 3. Ingest big data files\n",
    "\n",
    "\n",
    "Let us focus on a bigger file, `labevents.csv.gz`, which is about 125x bigger than `admissions.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edfd22f7-e1a5-4f5a-aca5-04ce598569f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 kose  staff  1939088924 May  3 14:10 /Users/kose/mimic/hosp/labevents.csv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ~/mimic/hosp/labevents.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a01b57-8d97-4107-aa33-8b64aa97b048",
   "metadata": {},
   "source": [
    "Display the first 10 lines of this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b0364a-21d8-434f-9bba-5b35cbd47c15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labevent_id,subject_id,hadm_id,specimen_id,itemid,order_provider_id,charttime,storetime,value,valuenum,valueuom,ref_range_lower,ref_range_upper,flag,priority,comments\r\n",
      "1,10000032,,45421181,51237,P28Z0X,2180-03-23 11:51:00,2180-03-23 15:15:00,1.4,1.4,,0.9,1.1,abnormal,ROUTINE,\r\n",
      "2,10000032,,45421181,51274,P28Z0X,2180-03-23 11:51:00,2180-03-23 15:15:00,___,15.1,sec,9.4,12.5,abnormal,ROUTINE,VERIFIED.\r\n",
      "3,10000032,,52958335,50853,P28Z0X,2180-03-23 11:51:00,2180-03-25 11:06:00,___,15,ng/mL,30,60,abnormal,ROUTINE,NEW ASSAY IN USE ___: DETECTS D2 AND D3 25-OH ACCURATELY.\r\n",
      "4,10000032,,52958335,50861,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,102,102,IU/L,0,40,abnormal,ROUTINE,\r\n",
      "5,10000032,,52958335,50862,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,3.3,3.3,g/dL,3.5,5.2,abnormal,ROUTINE,\r\n",
      "6,10000032,,52958335,50863,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,109,109,IU/L,35,105,abnormal,ROUTINE,\r\n",
      "7,10000032,,52958335,50864,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,___,8,ng/mL,0,8.7,,ROUTINE,MEASURED BY ___.\r\n",
      "8,10000032,,52958335,50868,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,12,12,mEq/L,8,20,,ROUTINE,\r\n",
      "9,10000032,,52958335,50878,P28Z0X,2180-03-23 11:51:00,2180-03-23 16:40:00,143,143,IU/L,0,40,abnormal,ROUTINE,\r\n",
      "zcat: error writing to output: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!zcat < ~/mimic/hosp/labevents.csv.gz | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58352877-c834-4488-8ea3-7360c347a754",
   "metadata": {},
   "source": [
    "### (A). Ingest `labevents.csv.gz` by `pd.read_csv`\n",
    "\n",
    "Try to ingest `labevents.csv.gz` using `pd.read_csv`. What happens? If it takes more than 5 minutes on your computer, then abort the program and report your findings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9088997-7a48-4b0b-b331-afab3e837925",
   "metadata": {},
   "source": [
    "### (B). Ingest selected columns of `labevents.csv.gz` by `pd.read_csv`\n",
    "\n",
    "Try to ingest only columns `subject_id`, `itemid`, `charttime`, and `valuenum` in `labevents.csv.gz` using `pd.read_csv`.  Does this solve the ingestion issue? (Hint: `usecols` argument in `pd.read_csv`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c3479-c29f-4f4a-be2e-1cdad8bcb622",
   "metadata": {},
   "source": [
    "### (C). Ingest subset of `labevents.csv.gz`\n",
    "\n",
    "Back in BIOSTAT 203B, our first strategy to handle this big data file was to make a subset of the `labevents` data.  Read the [MIMIC documentation](https://mimic.mit.edu/docs/iv/modules/hosp/labevents/) for the content in data file `labevents.csv.gz`.\n",
    "\n",
    "As before, we will only be interested in the following lab items: creatinine (50912), potassium (50971), sodium (50983), chloride (50902), bicarbonate (50882), hematocrit (51221), white blood cell count (51301), and glucose (50931) and the following columns: `subject_id`, `itemid`, `charttime`, `valuenum`. \n",
    "\n",
    "Run the Bash command to extract these columns and rows from `labevents.csv.gz` and save the result to a new file `labevents_filtered.csv.gz` in the current working directory (Q2.3 of HW2). How long does it take?\n",
    "(_You may reuse the file you created last quarter and report the elapsed time from the last quarter for this part._)\n",
    "\n",
    "Display the first 10 lines of the new file `labevents_filtered.csv.gz`. How many lines are in this new file? How long does it take `pd.read_csv()` to ingest `labevents_filtered.csv.gz`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422d0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35433429-4df8-4d6f-adbf-93dbb35b7ac2",
   "metadata": {},
   "source": [
    "### (D). Review\n",
    "\n",
    "Write several sentences on what the Parquet format, DuckDB, and polars are. Imagine you want to explain it to a layman in an elevator, as you did before. (It's OK to copy-paste the sentences from your previous submission.)\n",
    "\n",
    "Also, now is the good time to review [basic SQL commands](https://ucla-biostat-203b.github.io/2024winter/slides/12-dbplyr/dbintro.html) covered in BIOSTAT 203B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3682f8",
   "metadata": {},
   "source": [
    "### (E) Transform `labevents.csv.gz` to `.parquet` format and ingestion with DuckDB\n",
    "\n",
    "Often, `.csv.gz` format results in major bottleneck in high-performance data processing due to its compression. It's simple to change the data format using DuckDB: run the following cell to transform the `labevents.csv.gz` to `.parquet` format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "duckdb.sql(\"\"\"\n",
    "    COPY (\n",
    "        SELECT * FROM read_csv('~/mimic/hosp/labevents.csv.gz')\n",
    "    ) TO 'labevents.parquet' (FORMAT 'parquet')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eda104",
   "metadata": {},
   "source": [
    "Then, let's use the `duckdb` package in Python to use the DuckDB interface. In Python, DuckDB can interact smoothly with `pandas` and `polars`. I recommend reading: \n",
    "\n",
    "- https://duckdb.org/2021/05/14/sql-on-pandas.html\n",
    "- https://duckdb.org/docs/stable/guides/python/polars.html\n",
    "\n",
    "In Python, you will mostly use SQL commands to work with DuckDB. Check out the [data ingestion API](https://duckdb.org/docs/api/python/data_ingestion).\n",
    "\n",
    "\n",
    "Ingest the Parquet file, select columns, and filter rows as in (G). How long does the ingest+select+filter process take? Please make sure to call `.pl()` method to have the final result as a `polars` `DataFrame`. Display the number of rows and the first 10 rows of the result dataframe and make sure they match those in (C). \n",
    "\n",
    "__This should be significantly faster than the results before (but not including) Part (D).__ \n",
    "_Hint_: It could be a single SQL command.\n",
    "\n",
    "    \n",
    "- Finally, let's obtain the result in `polars` `DataFrame` using the method `.pl()`. \n",
    "\n",
    "How long does the ingest+select+filter process take? Display the number of rows and the first 10 rows of the result dataframe, and make sure they match those of (C).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee442e-4a62-4548-83bb-1ff3d70b8661",
   "metadata": {},
   "source": [
    "### (F). Polars\n",
    "\n",
    "Let's ingest the data with polars this time. Let's first try `pl.read_parquet()` function to load the data. Does it work on your computer? If so, how long does it take? Why is this happening? (If it runs over several minutes, you may just stop running the kernel, like above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e4116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "872b05e9",
   "metadata": {},
   "source": [
    "Actually, this is a great alternative -- lazy evaluation. Replace `pl.read_parquet()` with  `pl.scan_parquet()`, and observe the difference. What would be the biggest difference between `pl.read_parquet()` and  `pl.scan_parquet()` under this scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7782e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b97f3d1-0916-4c2c-a217-000107309c7e",
   "metadata": {},
   "source": [
    "### (G). Comparison\n",
    "Compare your results between Part (E) and (F); and along with the results from Homework 2 of BIOSTAT 203B. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02da79d3-c8ec-4785-a9c3-3a5fc63de358",
   "metadata": {},
   "source": [
    "## Problem 4. Ingest and filter `chartevents.csv.gz`\n",
    "\n",
    "[`chartevents.csv.gz`](https://mimic.mit.edu/docs/iv/modules/icu/chartevents/) contains all the charted data available for a patient. During their ICU stay, the primary repository of a patient’s information is their electronic chart. The `itemid` variable indicates a single measurement type in the database. The `value` variable is the value measured for `itemid`. The first 10 lines of `chartevents.csv.gz` are\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1f3a0-6342-42f9-9902-44030612c6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zcat < ~/mimic/icu/chartevents.csv.gz | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e290e-44cf-4ac8-9060-43d96bef0160",
   "metadata": {},
   "source": [
    "[`d_items.csv.gz`](https://mimic.mit.edu/docs/iv/modules/icu/d_items/) is the dictionary for the `itemid` in `chartevents.csv.gz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd8d66-0961-4f95-9f02-f576fb7a07c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!zcat < ~/mimic/icu/d_items.csv.gz | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f757e5-9637-4549-b746-1aefce427a75",
   "metadata": {},
   "source": [
    "Again, we are interested in the vitals for ICU patients: heart rate (220045), mean non-invasive blood pressure (220181), systolic non-invasive blood pressure (220179), body temperature in Fahrenheit (223761), and respiratory rate (220210). Retrieve a subset of `chartevents.csv.gz` only containing these items, using the favorite method you learned in Problem 3. \n",
    "\n",
    "Document the steps and show your code. Display the number of rows and the first 10 rows of the result `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba47e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
